# RuneScape Wiki Anti-ChatGPT for PT-BR Articles

This is a model trained to detect RSW articles translated to PT-BR using machine translation, mainly ChatGPT and Gemini. Although detecting if a piece of text is machine-generated or not is very, VERY hit-or-miss, this scenario differs because there are clear differences between one and the other.

## Text anomalies

In a machine translation of an article, alot of Template parameters tend to be left untranslated. Not only that, but Template names, item names and even headers tend to be wrongfully translated. Examples include:

* `Augumented staff of Sliske` → `cajado de Sliske aumentado`;
    * Should've been "cajado de Sliske aprimorado". 
* `{{Hastranscript}}` → `{{Possui transcrição}}`;
    * Should've been "{{TemDiálogo}}"
* `==Combat stats==` → `==Atributos de combate==`
    * Should've been "==Estatísticas de combate=="

## Training data

I scrapped every single page from the English RSW that included a PT-BR equivalent, ignoring non-article pages such as discussions, Templates and whatnot. Then, for each page, I ran its source-code throught Gemini's flash-2.5 model to generate me a translation. After that, both the translated English and actual PT-BR articles got split by their sections (headers) and compiled into a csv file.

For the sake of time and also Google's API limits, since this is only a proof-of-concept, I only processed up to the middle of the articles starting with the letter "A". This includes articles whose names start with symbols such as a single quotation mark.

Adding together the articles from both wikis, plus splitting, that's about 4.9K entries of training data.

## The model

At first I thought about using a hybrid CNN-BiLSTM deep learning model, but between issues installing TensorFlow and figuring it might be overkill, I ended up opting for a simpler sklearn Pipeline using TfidfVectorizer and LinearSVC. I also thinkered with BERT for shits and giggles, but that's a whole space armada just to nuke a single pigeon off the streets.

### Results
With 20% of data reserved for testing, the results came as such:

| | precision | recall | f1-score | support |
| :--- | :--- | :--- | :--- | :--- |
| **Bad** | 0.93 | 0.96 | 0.94 | 612 |
| **Good**| 0.92 | 0.87 | 0.90 | 363 |
| | | | | |
| **accuracy** | | | 0.93 | 975 |
| **macro avg** | 0.92 | 0.91 | 0.92 | 975 |
| **weighted avg** | 0.93 | 0.93 | 0.92 | 975 |

By manually asking both ChatGPT-5 and Gemini 2.5 Pro for some translations, I tested sections of the following pages (both en-translated and actual pt-br). Every single prediction came out correct:

- [Zaros godsword](https://runescape.wiki/w/Zaros_godsword);
- [Staff of Sliske](https://runescape.wiki/w/Staff_of_Sliske);
- [Bryll shoes](https://runescape.wiki/w/Bryll_shoes);
- [Museum - Bandosian II](https://runescape.wiki/w/Museum_-_Bandosian_II);
- [Vorago](https://runescape.wiki/w/Vorago);
- [Legionary remains](https://runescape.wiki/w/Legionary_remains)

### Shortcommings

- LinearSVC is almost as basic as you can go;
- The model was trained on a relatively small dataset;
- The english-translated parts of the training data were only generated by Gemini-2.5-flash. It would've been nice to get some more variety going;
- The model will probably fail on more text-heavy articles, that involve less Templates, headers or item-naming (such as NPC or Quest articles);
- Those generative models probably don't know gaming/wiki terminologies because it's a niche thing and they're often outdated by the time they're released, but this could change in the future, making the machine translation less scuffed and difficult to weed out.